{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningtools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CPU, if use GPU, choose the GPU device #\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 planet masses, 3 hr and 3 alpha \n",
    "# 3 dust size slopes, 3.5, 3 and 2.5, they are too similar, so we only use 3.5.\n",
    "# 32 combinations of amax of \n",
    "# 5 inclinations and 24 position angles\n",
    "# the image size is 64 x 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download simimgs.npy from http://www.physics.unlv.edu/~shjzhang/simimgs.npy\n",
    "! cd ../data/\n",
    "! wget http://www.physics.unlv.edu/~shjzhang/simimgs.npy\n",
    "! cd notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3, 1, 32, 5, 24, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "subset = np.load(\"../data/simimgs.npy\")\n",
    "print (subset.shape)\n",
    "subset = subset[:, :, :, 0, :, : , :, :, :]\n",
    "# (5, 3, 3, 1, 32, 5, 24, 64, 64)\n",
    "\n",
    "# planet mass\n",
    "y = np.zeros(subset.shape[:-2], dtype=int)\n",
    "for i in range(5):\n",
    "    y[i] = i\n",
    "    \n",
    "x = subset.reshape(-1, subset.shape[-4], subset.shape[-3], subset.shape[-2], subset.shape[-1])\n",
    "y = y.reshape(-1, subset.shape[-4], subset.shape[-3])\n",
    "\n",
    "# shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "index = np.arange(np.cumprod(subset.shape)[3])\n",
    "np.random.shuffle(index)\n",
    "\n",
    "x = x[index]\n",
    "y = y[index]\n",
    "\n",
    "x = x.reshape(-1, 64, 64)\n",
    "y = y.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xprime = np.zeros_like(x)\n",
    "for i in range(x.shape[0]):\n",
    "    xnew = x[i]  + 0.1*np.std(x[i])* np.random.random( (64, 64) )\n",
    "    xnew = (np.log10(xnew) - np.log10(xnew.max()) + 2.) / 2.\n",
    "    xprime[i] = xnew \n",
    "xprime[xprime < 0] = 0\n",
    "x = xprime\n",
    "\n",
    "# split trainig, validation and test data to 60%, 20% and 20%.\n",
    "# 0.6: 0.2: 0.2\n",
    "x_train = x[:int(x.shape[0]*0.6)]\n",
    "y_train = y[:int(x.shape[0]*0.6)]\n",
    "\n",
    "x_val = x[int(x.shape[0]*0.6):int(x.shape[0]*0.8)]\n",
    "y_val = y[int(x.shape[0]*0.6):int(x.shape[0]*0.8)]\n",
    "\n",
    "x_test  = x[int(x.shape[0]*0.8):]\n",
    "y_test  = y[int(x.shape[0]*0.8):]\n",
    "\n",
    "index = np.arange(y_train.shape[0])\n",
    "np.random.seed(0) \n",
    "np.random.shuffle(index)\n",
    "x_train = x_train[index]\n",
    "y_train = y_train[index]\n",
    "\n",
    "\n",
    "index = np.arange(y_val.shape[0])\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(index)\n",
    "x_val = x_val[index]\n",
    "y_val = y_val[index]\n",
    "\n",
    "index = np.arange(y_test.shape[0])\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(index)\n",
    "x_test = x_test[index]\n",
    "y_test = y_test[index]\n",
    "\n",
    "x_train = x_train[:,:,:,None]\n",
    "x_val = x_val[:,:,:,None]\n",
    "x_test = x_test[:,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 128  # orig paper trained all networks with batch_size=128\n",
    "EPOCHS = 100 # 200\n",
    "USE_AUGMENTATION = False\n",
    "NUM_CLASSES = np.unique(y_train).shape[0] # 10\n",
    "COLORS = x_train.shape[3]\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "SUBTRACT_PIXEL_MEAN = True\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), \n",
    "# Improved ResNet: version = 2 \n",
    "# (ResNet v2)\n",
    "VERSION = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if VERSION == 1:\n",
    "    DEPTH = 2*COLORS * 6 + 2\n",
    "    #DEPTH = COLORS * 6 + 2\n",
    "elif VERSION == 2:\n",
    "    DEPTH = 2*COLORS * 9 + 2\n",
    "SUBTRACT_PIXEL_MEAN = False\n",
    "\n",
    "decay_steps = 100\n",
    "initial_learning_rate = 5e-3\n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "    initial_learning_rate, decay_steps)\n",
    "def lr_schedule(x):\n",
    "    return float(lr_decayed_fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (103680, 64, 64, 1)\n",
      "103680 train samples\n",
      "34560 test samples\n",
      "y_train shape: (103680,)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 16)   160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   1088        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   1088        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 16)   1040        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           add[0][0]                        \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   4160        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  8320        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 128)  8320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   8256        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 128)  8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  16512       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 256)  33024       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 128)  32896       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 256)  33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 2, 2, 256)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            5125        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 576,357\n",
      "Trainable params: 572,869\n",
      "Non-trainable params: 3,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if SUBTRACT_PIXEL_MEAN:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# Create the neural network\n",
    "if VERSION == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=DEPTH, num_classes=5)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=DEPTH, num_classes=5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Takes several days on a PC to train.\n",
    "# On mbp 2019, it takes 2.5 days.\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "#lr_scheduler = LearningRateScheduler(lr_decayed_fn)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not USE_AUGMENTATION:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              validation_data=(x_val, y_val),\n",
    "              shuffle=False,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation \n",
    "        # (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, \n",
    "                        batch_size=BATCH_SIZE),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=EPOCHS, verbose=0, workers=1,\n",
    "                        callbacks=callbacks, \n",
    "                        use_multiprocessing=False)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "#print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 hours to train on a GPU.\n",
    "# takes very 2.5 days to train on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/resnet/model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
